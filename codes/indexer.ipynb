{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexer pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dependecies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = \"../data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Validation Dataset (MedQuAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16407 entries, 0 to 16406\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   question  16407 non-null  object\n",
      " 1   answer    16407 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 256.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is (are) keratoderma with woolly hair ?</td>\n",
       "      <td>Keratoderma with woolly hair is a group of rel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How many people are affected by keratoderma wi...</td>\n",
       "      <td>Keratoderma with woolly hair is rare; its prev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the genetic changes related to kerato...</td>\n",
       "      <td>Mutations in the JUP, DSP, DSC2, and KANK2 gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is keratoderma with woolly hair inherited ?</td>\n",
       "      <td>Most cases of keratoderma with woolly hair hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are the treatments for keratoderma with w...</td>\n",
       "      <td>These resources address the diagnosis or manag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  \\\n",
       "0       What is (are) keratoderma with woolly hair ?   \n",
       "1  How many people are affected by keratoderma wi...   \n",
       "2  What are the genetic changes related to kerato...   \n",
       "3        Is keratoderma with woolly hair inherited ?   \n",
       "4  What are the treatments for keratoderma with w...   \n",
       "\n",
       "                                              answer  \n",
       "0  Keratoderma with woolly hair is a group of rel...  \n",
       "1  Keratoderma with woolly hair is rare; its prev...  \n",
       "2  Mutations in the JUP, DSP, DSC2, and KANK2 gen...  \n",
       "3  Most cases of keratoderma with woolly hair hav...  \n",
       "4  These resources address the diagnosis or manag...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medquad = pd.read_json(f\"{dir_data}validations/medquad.json\", orient=\"records\")\n",
    "medquad.info()\n",
    "medquad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Publications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rögzített hosszúságú chunk-ok (Fixed-length chunking)\n",
    "\n",
    "- **Hivatkozás:** Devlin, J., Chang, M. W., Lee, K., & Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (pp. 4171-4186). https://doi.org/10.18653/v1/N19-1423\n",
    "- **Állítás:** A rögzített hosszúságú chunk-ok használata gyakori a BERT alapú modellekben, ahol a dokumentumokat egy meghatározott hosszúságú (512 tokenes) egységekbe bontják."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Mondat- vagy bekezdés-alapú darabolás (Sentence/Paragraph-based chunking)\n",
    "\n",
    "- **Hivatkozás:** Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., ... & Petrov, S. (2019). Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics, 7, 453-466. https://doi.org/10.1162/tacl_a_00276\n",
    "- **Állítás:** Itt a mondat- és bekezdés-alapú chunking módszer a kérdés-válasz rendszerek fejlesztésében alkalmazott módszert illusztrálja, amely függetlenül kezeli a hosszú és rövid válaszokat a dokumentumból kinyert mondat- vagy bekezdésszintű egységek alapján."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window (csúszóablak) módszer\n",
    "\n",
    "- **Hivatkozás:** Beltagy, I., Peters, M. E., & Cohan, A. (2020). Longformer: The long-document transformer. arXiv preprint arXiv:2004.05150. https://arxiv.org/abs/2004.05150\n",
    "- **Állítás:** Az idézet alátámasztja a csúszóablakos módszert, amely csökkenti a hosszú szövegek feldolgozásának költségeit, miközben megőrzi a szöveg összefüggését, és a dokumentum több ezer tokenes feldolgozását is lehetővé teszi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchikus chunking\n",
    "\n",
    "- **Hivatkozás:** Luong, T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (pp. 1412-1421). https://doi.org/10.18653/v1/D15-1166\n",
    "- **Állítás:** A hierarchikus chunking megközelítés itt úgy jelenik meg, hogy a figyelmet több szinten alkalmazzák (szó- és mondatszinten), ami lehetővé teszi a modellek számára, hogy a különböző szintű kontextusokat figyelembe vegyék a szövegek feldolgozása során."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dinamikus chunking tokenlimittel\n",
    "\n",
    "- **Hivatkozás:** Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., ... & Amodei, D. (2020). Language models are few-shot learners. Advances in Neural Information Processing Systems, 33, 1877-1901. https://arxiv.org/abs/2005.14165\n",
    "- **Állítás:** A dinamikus chunking módszer ebben a kontextusban figyelmet fordít arra, hogy a természetes mondathatárok mentén darabolja fel a szöveget, így a GPT-3 modell optimálisan használja a 2048 tokenes kontextusablakát anélkül, hogy fontos információkat truncálna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
